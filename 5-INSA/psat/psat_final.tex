\documentclass[runningheads]{llncs}

\usepackage{geometry}
\geometry{hmargin=4cm, vmargin=4.17cm}

\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{color}
\usepackage{epigraph}
\usepackage{dirtytalk}
\usepackage{array}
\usepackage{microtype}
\usepackage{tabularx}
\usepackage[table]{xcolor}% http://ctan.org/pkg/xcolor
\usepackage{appendix}

\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}

\pagestyle{plain}



% display URLs in blue roman font according to Springer's eBook style
\renewcommand\UrlFont{\color{blue}\rmfamily}

\begin{document}

\title{Analyse du ciblage géographique} 

\author{
    Ludovic Richoux \and
    Aymeric Cousaert \and
    Téo Bouvard \and 
    Mathis Guilhin
}

% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\authorrunning{F. Author et al.}

\institute{
    \href{https://www.insa-lyon.fr/}{INSA Lyon}
    \email{\href{mailto:psat01@protonmail.com}{psat01@protonmail.com}}
}

\maketitle

\epigraph{
    Arguing that you don't care about the right to privacy because you have nothing to hide is no different than saying you don't care about free speech because you have nothing to say. \cite{edward_snowden_riama_2015}}{\textit{Edward Snowden}
}

\begin{abstract}

L'adoption massive des smartphones a permis l'émergence de services et d'applications dont la valeur repose sur une connaissance contextuelle de l'utilisateur. L'utilisation de technologies liées à la géolocalisation permet d'alimenter cette connaissance, mais entraîne également un traçage de l'utilisateur, bien souvent à son insu. À travers nos travaux, nous proposons une analyse du ciblage publicitaire sur smartphone. Pour cela, nous abordons, dans un premier temps, les techniques mises en place afin d'instrumentaliser un téléphone pour générer une position fictive cohérente. Nous proposons ensuite des méthodes de collecte de données publicitaires présentes sur les applications mobiles de réseaux sociaux. Enfin nous analysons les liens entre les données publicitaires collectées et la position de l'utilisateur. 
%Ajouter qq chiffres si possible


\keywords{Ciblage publicitaire \and Géolocalisation}

\end{abstract}

\section{Introduction}

L'adoption massive des smartphones~\cite{pew_research_center_demographics_2019} a fait apparaître de plus en plus de services et d'applications personnalisés. Afin de proposer le meilleur service possible, certaines plateformes comme Google Maps, Facebook ou encore Uber mettent à profit leur connaissance approfondie de l'utilisateur. L'utilisation de technologies telles que le GPS, le Wi-Fi, le Bluetooth et les données mobiles permettent de déterminer et transmettre des informations géolocalisées en temps réel à ces services et ainsi offrir à l'utilisateur une expérience personnalisée en fonction de sa position.

Cependant l'utilisation de ces technologies permet également un traçage de l'utilisateur, bien souvent à son insu~\cite{almuhimedi_your_2015}. Depuis quelques années, notamment avec les évènements liés aux élections américaines de 2016~\cite{robert_mueller_report_2019} ou le scandale du Cambridge Analytica~\cite{isaak_user_2018}, on observe une prise de conscience concernant l'utilisation des données personnelles, qui incluent les données de localisation. Il reste néanmoins difficile de savoir qui collecte ces données et quelle utilisation en est faite. Ces données peuvent notamment être utilisées par des compagnies publicitaires qui sont capables d'affiner leur filtrage d'audience en utilisant les lieux visités par les utilisateurs à l'aide du \textit{geofencing}~\cite{google_geofencing_2020}. Ces publicités peuvent être diffusées sur des réseaux sociaux comme Facebook~\cite{facebook_for_buisness_a_2020}, Twitter~\cite{twitter_geo_2020} ou encore Instagram. Ces plates-formes sont utilisées massivement dans le monde entier et sont majoritairement financées par la publicité. Aussi, il est possible d'observer certaines dérives liées à l'utilisation de la publicité ciblée. Par exemple, la présence d'un utilisateur à proximité d'évènements politiques peut aboutir à une proposition de contenu sponsorisé pour un candidat ou un parti politique et ainsi potentiellement l'influencer lors d'élections~\cite{bradshaw_challenging_nodate}.

Cette problématique d'actualité, ravivée par les élections présidentielles aux États-Unis en Novembre 2020, est d'ailleurs à l'origine du bannissement permanent des contenus sponsorisés à caractère politique par Twitter et la prolongation de celui-ci par Google et Facebook~\cite{hannah_murphy_facebook_2020}. Plusieurs études proposent des méthodes d'extraction et d'analyse de contenus publicitaires résultant d'un ciblage géographique afin de comprendre les pratiques mises en place~\cite{nick_anstead_political_2018}. Cependant, ces études reposent sur des publicités extraites depuis un ordinateur grâce à des méthodes de web scraping. Hors, les clients web fournissent des données de localisation moins fines que les smartphones. De plus, l'utilisation d'appareils mobile pour accéder à internet est en plein essor. En effet, en février 2019, 48\% du trafic internet mondial était issu d'appareils mobiles~\cite{jclement_topic_2019}.


L'objectif de ces travaux est donc d'étudier les liens entre le ciblage publicitaire et les systèmes de géolocalisation. Pour mener cette analyse, nous devons dans un premier temps instrumentaliser la position d'un smartphone. Nous avons couplé l'utilisation d'une radio logicielle pour générer un signal GPS fictif, à l'émission de points d'accès Wi-Fi et Bluetooth à proximité de cette position et d'un VPN. L'utilisation simultanée de ces techniques permet d'augmenter la cohérence de la position simulée et de diminuer la probabilité d'être détecté comme position fictive. Dans un second temps, nous avons organisé une collecte de contenus sponsorisés sur smartphone. L'objectif est de collecter les données publicitaires sur des applications de réseaux sociaux comme Facebook ou Twitter. L'utilisation des API de ces sites ne nous permettant pas l'accès aux contenus sponsorisés, nous avons mis en place deux techniques de collecte. La première consiste à réaliser des impressions écrans des fils d'actualités et d'en extraire les contenus sponsorisés à l'aide de reconnaissance optique de caractères. La seconde repose sur l'interception des paquets dans le cadre d'une attaque de type \textit{Man In The Middle}.

 Dans ce papier, nous dressons tout d'abord l'état de l'art sur les technologies de géolocalisation et d'instrumentalisation de la position d'un smartphone (Section~\ref{instrumentalisation_position}). Nous étudions ensuite les méthodes de collecte de données publicitaires existantes sur ordinateur (Section~\ref{collecte_web}). Nous proposons ensuite de nouvelles méthodes d'instrumentalisation de la position et de collecte de contenu sponsorisé sur smartphone (Section~\ref{collecte_mobile}). Nous évoquons enfin des méthodes d'analyse des données collectées (Section~\ref{analyse_dataset}), avant de conclure (Section~\ref{conclusion}).

\section{État de l'art}

\subsection{Géolocalisation}

L'adoption massive des smartphones a permis le développement à grande échelle des systèmes de géolocalisation embarqués. Ainsi, les systèmes d'exploitation Android~\cite{google_how_2020} et iOS~\cite{apple_location_2020} proposent des services de géolocalisation avancés permettant de déterminer précisément la position d'un utilisateur en utilisant non seulement le module GPS du smartphone, mais aussi l'adresse IP qui lui est assignée, les appareils Bluetooth et les points d'accès Wi-Fi environnants, ainsi que les antennes relais de téléphonie mobile captés. À l'origine, ces données complémentaires étaient collectées de manière centralisée comme lors de l'initiative Street View~\cite{peter_fleischer_data_2010}. 
Cependant, ces informations sont désormais collectées de manière distribuée par les utilisateurs des services de géolocalisation. Cette collecte continue permet de constituer un maillage mondial d'adresses MAC et d'identifiants d'antennes relais mis à jour en temps réel qui permet de déterminer avec précision la position d'un appareil sans même avoir recours au GPS~\cite{google_overview_2020}.
Ces bases de données sont privées, mais il existe des initiatives publiques telles que le projet WiGLE~\cite{bobzilla_wigle_2020}, qui permet à des utilisateurs de publier volontairement les informations que Google et Apple collectent de manière automatique. Depuis 2001, cette base de données a permis de collecter 696 millions de points d'accès Wi-Fi uniques, 351 millions d'appareils Bluetooth et 14 millions d'antennes relais, et ceci grâce à seulement 292 000 utilisateurs. Ces statistiques permettent d'imaginer l'importance des bases de données d'Apple ou de Google qui sont mises à jour en temps réel par plusieurs milliards d'appareils~\cite{google_google_2019}.

\begin{sloppypar}
Toutefois, ces systèmes de géolocalisation sont susceptibles d'être manipulés. L'instrumentalisation de la position consiste à manipuler les données reçues par un appareil afin que ce dernier génère une position fictive choisie par l'attaquant. Cette attaque peut être basée uniquement sur la diffusion d'un signal GPS malicieux~\cite{huang_low-cost_2015,liu_all_2018}, mais elle peut aussi être augmentée en utilisant les informations complémentaires utilisées par les systèmes de géolocalisation tel que les informations émanant du Wi-Fi, du Bluetooth, ou du GSM. C'est l'approche que nous tentons d'explorer dans ce projet. Cependant, l'algorithme de détermination de la position qui utilise ces différentes données reste inconnu, et nous devons donc le traiter comme une boîte noire (Figure~\ref{fig:blackbox}).
\end{sloppypar}

\begin{figure}
\centering
\includegraphics[width=0.3\linewidth]{geolocation_vectors.pdf}
\caption{L'algorithme de détermination de la position reste une boite noire}
\setlength{\belowcaptionskip}{-10pt}
    \label{fig:blackbox}
\end{figure}

De plus, certaines subtilités nous échappent encore, notamment en relation avec les permissions du téléphone. Dans les paramètres, il est possible de choisir entre plusieurs modes pour que le téléphone détermine notre localisation : GPS uniquement ou Fused Location (GPS + Bluetooth + Wi-Fi + réseaux mobiles). Cependant, même en sélectionnant la première option (GPS uniquement) et en désactivant le GPS, nous arrivons à obtenir une position très précise sur Google Maps. Le champ d'application de ces permissions n'est donc pas parfaitement défini et nous ne pouvons pas nous reposer dessus pour limiter les variables influant sur la détermination de notre localisation.

L'exposition grandissante des données de géolocalisation soulève de nouveaux problèmes éthiques. Malgré le fait que ces informations puissent avoir un réel intérêt pour le bien commun, comme c'est le cas pour la modélisation des flux de déplacements urbains~\cite{calacci_tradeoff_2019}, elles peuvent aussi menacer la vie privée des individus. Daniel le Metayer, directeur de recherche au centre de recherche Inria Grenoble et spécialiste en protection de la vie privée dit \say{\textit{la valeur de la vie privée ne se réduit pas à la possibilité de cacher des choses répréhensibles ou honteuses : la possession d’une aire intime, privée, est nécessaire au développement de la personnalité, à l’émancipation de chacun}}. En effet, en rendant accessibles nos informations de mobilité, qui sont des données à la fois personnelles et sensibles, nous réduisons notre aire intime. De plus, le traitement et le croisement de ces informations de mobilité avec des connaissances auxiliaires (statistiques INSEE, modèles d'apprentissage) permet d'inférer de multiples informations sur un individu, comme son lieu d'habitation et de travail, son sexe, mais aussi ses traits de caractères et ses centres d'intérêts~\cite{boutet_inspect_2019}.

D'autre part, cette collecte de données géolocalisées peut avoir des conséquences néfastes majeures sur la vie privée : nous n'avons pas de contrôle sur l'utilisation de ces données, qui peuvent être utilisées par des gouvernements, institutions et entreprises. Par exemple, aux Etats-Unis, la police peut avoir recours à des \textit{Geofence warrant} (mandat de géorepérage) afin d'identifier les personnes présentes à une manifestation qui aurait dégénéré. Dès lors, une personne passant par cette endroit sans forcément être impliquée dans les délits peut-être incriminée \cite{chatrie_united_2019}. En Europe cependant, le RGPD permet aux utilisateurs finaux d'avoir un meilleur contrôle sur leurs données personnelles, et limite strictement l'accès à ces données par des acteurs extérieurs.

Une étude dans une station de train à Melbourne~\cite{cabalquinto_it_2020} nous renseigne sur la manière dont les utilisateurs sont enclins à partager leurs données avec des institutions publiques et gouvernementales pour améliorer l'expérience et la sécurité des usagers. Il se trouve alors que si les personnes concernées sont davantage renseignées sur la manière dont leurs informations sont traitées et sécurisées, elles sont plus enclines à les mettre au service du bien commun.

Enfin, même après avoir été anonymisées, certaines attaques permettent de ré-identifier le propriétaire de la trace de mobilité avec une probabilité élevée, dans le cas ou une partie de la donnée aurait été exposée~\cite{zhang_asynchronous_2018}.
%Enfin, ces données de géolocalisation sont parfois collectées et publiées pour mener des études scientifiques \cite{mokhtar_privamov_2017}, après avoir été anonymisées \cite{primault_privacy-preserving_2015}. Toutefois, des attaques comme une \textit{Asynchronous side information attack from the edge} permettraient d'identifier le propriétaire de la trace avec une probabilité élevée, dans le cas ou une partie de la donnée aurait été exposé \cite{zhang_asynchronous_2018}. 
En effet, quel que soit le type de collecte utilisé (GPS, Wi-Fi ou antennes GSM), chaque trace se révèle hautement unique~\cite{boutet_uniqueness_2016}. Pour un dataset où la localisation est renseignée toutes les heures avec la précision des antennes de téléphonie, 4 données spatio-temporelles suffisent pour identifier un utilisateur avec une probabilité de 95\% \cite{montjoye_unique_2013}.


\subsection{Ciblage publicitaire}

La source de revenu majoritaire des réseaux sociaux provient des publicités qu'ils proposent à leur utilisateurs. Pour les annonceurs, ces plates-formes sont particulièrement intéressantes pour cibler les personnes qui reçoivent la publicité car ils fournissent de nombreuses informations telles que la localisation, l'âge, le genre et l'orientation sexuelle, les centres d'intérêts et les interactions sociales. Le ciblage publicitaire politique sur les réseaux sociaux est donc un outil potentiellement puissant pour les campagnes politiques~\cite{maruyama_hybrid_2014}, mais le pouvoir est également dans les mains des réseaux sociaux eux-mêmes, qui ont un droit de veto sur le contenu éligible à la publication sur leurs plates-formes et peuvent bannir les publicités durant certaines périodes. C'est le cas de Facebook et Google qui ont interdit les publicités politiques pendant la période des élections aux États-Unis en 2020~\cite{hannah_murphy_facebook_2020}. Proposer des publicités personnalisées afin d'avoir un plus fort impact sur l'utilisateur, c'est aussi donner du pouvoir à la manipulation via les fake news, qui peuvent être proposées aux utilisateurs sous forme de contenu sponsorisé malicieux~\cite{ribeiro_microtargeting_2019}.

A la suite du scandale Cambridge Analytica, Facebook et Twitter ont réduit l'accès à leurs APIs~\cite{axel_bruns_after_2019}. En conséquence, nous avons du mettre en place d'autres techniques pour extraire les contenus sponsorisés proposés aux utilisateurs, comme par exemple du \textit{web scraping}. Ce terme désigne un ensemble de techniques permettant d'obtenir automatiquement les informations présentées par un site web sans avoir à y naviguer manuellement. Cette pratique permet notamment d'extraire certains contenus des pages web afin de les transformer puis de les stocker dans une structure de données appropriée. 

Une collecte de publicités Facebook a été réalisée au Brésil pour analyser les publicités à l'occasion des élections présidentielles en 2018~\cite{silva_facebook_2020}. Les publicités collectées sont ensuite triées pour en extraire celles à caractère politique à l'aide d'algorithmes de classification supervisés. Il est constaté que certaines publicités politiques ainsi identifiées ne sont pas considérés dans l'API Facebook comme ayant une composante politique. % TODO est-ce un bypass des annonceurs ou Facebook laisse passer ? Développer -> pas plus d'infos dans le papier de Silva, seulement que la loi Brésilienne et les conditions d'utilisations des pub Facebook ne sont pas nécéssairement appliquées.
% discuter du fait que cela est fait délibérément ou non ?


Un jeu de données de publicités récolté par ProPublica en 2018 est analysé pour identifier quels attributs d'un utilisateur en font un bon sujet pour recevoir des publicités politiques \cite{levi_automatically_2020}. Les publicités politiques sont ici extraites à l'aide d'une classification de texte naïve bayésienne sur les publicités indexées. Dans ces recherches, la région est identifiée comme le deuxième critère après l'âge pour faire du ciblage publicitaire. 


Avec les smartphones, les annonceurs ont accès à davantage  d'éléments géographiques pour réaliser un ciblage publicitaire, en proposant des publicités spécifiques aux lieux de déplacement. Sur Android, Google permet aux développeurs de créer des géofences, c'est à dire de choisir une zone géographique dans laquelle une application peut opérer différemment. On peut alors se demander quel est le degré de granularité géographique proposé pour le ciblage publicitaire sur les différents réseaux sociaux. Sur Facebook, les annonceurs peuvent choisir le lieu d'exposition de leur publicités, en particulier le pays, la région, la ville, le code postal, les coordonnées géographiques avec un rayon (latitude, longitude), ou la circonscription électorale. Ils peuvent également choisir le type du lieu : si l'utilisateur est chez lui (localisation identique à la ville renseignée sur son profil), en vacances (localisation différente à la ville renseignée sur son profil, et avec plus de 100 miles de distance) ou s'il est simplement en déplacement \cite{noauthor_ciblage_nodate}. Sur Twitter, il est possible de cibler un ensemble de pays, régions, zones urbaines, ou codes postaux. 

Le ciblage géographique n'est pas seulement d'utilité pour les annonceurs. Sur le moteur de recherche Google, les suggestions proposées pour compléter la recherche dépendent de la localisation. Le ciblage géographique peut également être un outil pour les autorités, qui peut obtenir un mandat afin de déterminer des informations sur un groupe d'utilisateurs présent dans une géofence particulière~\cite{ng_how_nodate}.


%Mais la possibilité d'utiliser la localisation pour recommander des services de proximité ou proposer des publicités personnalisées peut être une atteinte à la vie privée, par exemple en recommandant à des utilisateurs de se connecter à d'autres utilisateurs qui fréquentent les mêmes lieux. 
Aux Etats-Unis, les deux lois qui gouvernent les données de localisation sont l'Electronic Privacy Act de
1986 et le Communications Act de 1934. Ces deux lois ont été écrites bien avant les usages que l'on peut observer aujourd'hui, et pourraient donc ne plus être pertinentes vis à vis des usages actuels. Certains états ont approuvé des lois supplémentaires mais sont toujours en attente d'approbation, comme par exemple le Geolocation Privacy and Surveillance Act ou le Location Privacy Protection Act. En Europe, la collecte des données personnelles est régie par le RGPD, datant de 2018~\cite{karanja_unintended_2018}.


\section{Protocole expérimental}

Afin d'analyser l'impact de la position de l'utilisateur sur sa personnalisation de contenu, il est nécessaire d'instrumentaliser la géolocalisation du téléphone. 
Dans cette partie, nous expliquons les différentes stratégies que nous avons élaboré pour instrumentaliser la position du téléphone, créer des identités uniques sur les réseaux sociaux, et enfin collecter les publicités.


\subsection{Instrumentalisation de la position}\label{instrumentalisation_position}

Afin d'instrumentaliser la position d'un utilisateur fictif, nous tentons d'utiliser tous les vecteurs de détermination de position.

En ce qui concerne le GPS, nous déterminons au préalable un trajet qui ferait passer notre utilisateur fictif dans des zones identifiées comme potentiellement ciblées par des annonceurs politiques : lieux religieux, hôpitaux, bureaux de vote, clinique d'avortement. Nous dessinons une trace GPS de ce trajet à l'aide de l'outil \href{https://gpxstudio.github.io/}{GPX studio}. Les points GPS constituant ces traces sont ensuite convertis dans un repère \textit{Earth Centered Earth Fixed} afin de servir de données d'entrée à l'outil GPS-SDR-SIM ~\cite{osqzss_osqzssgps-sdr-sim_2020} qui, en utilisant un fichier d'éphéméride GNSS ~\cite{national_aeronautics_and_space_administration_gnss_2020}, permet de créer un signal GPS fictif simulant un déplacement le long de la trajectoire prédéfinie. Une fois généré, ce signal GPS est ensuite émis à l'aide d'une radio logicielle.

De manière plus détaillée, le GPS fonctionne par triangulation de signaux reçus par le téléphone. Plusieurs constellations de satellites (GPS, Galileo, GLONASS, BeiDou) émettent un signal radio en continu. Le signal radio émis par chaque satellite contient l'heure d'émission précise provenant d'une horloge atomique embarquée ainsi que la position du satellite déterminée à l'aide des lois de la mécanique orbitale ainsi que de corrections mesurées par des stations au sol dont les positions sont connue. La distance $D$ d'un récepteur à un de ces satellites peut donc être exprimée par la relation

\begin{equation}
    D = c(\tau + \Delta t)
\end{equation}

où $c$ représente la vitesse de déplacement de l'onde radio, $\tau$ le temps de propagation de l'onde de l'émetteur au récepteur et $\Delta t$ la différence de synchronisation d'horloge entre l'émetteur et le récepteur.

D'autre part, le théorème de Pythagore appliqué dans un repère ECEF, dans lequel le récepteur est immobile, nous donne la relation entre la position d'un satellite $i$ et du récepteur $r$.

\begin{equation}
    (x_i - x_r)^2 + (y_i - y_r)^2 + (z_i - z_r)^2 = D^2
\end{equation}

D'où l'équation de détermination de la position

\begin{equation}
    (x_i - x_r)^2 + (y_i - y_r)^2 + (z_i - z_r)^2 = c(\tau_i + \Delta t)^2
    \label{eq:position_determination}
\end{equation}

Cette équation comporte 4 inconnues ($x_r$, $y_r$, $z_r$, $\Delta t$) et nécessite donc la réception d'au moins 4 signaux provenant de satellites différents pour déterminer précisément la position du récepteur. 

Dans notre cas d'utilisation, nous cherchons à effectuer le calcul inverse : à partir de la position déterminée du récepteur (trajectoire prédéfinie) et celle des satellites (fichiers d'éphémérides), on calcule les $\tau_i$ vérifiant l'équation \ref{eq:position_determination}. Une fois ces délais de réception calculés, il est possible de construire les messages de navigation émis par les satellites et de les transmettre à l'aide de la radio logicielle.

Afin d'augmenter cette instrumentalisation, nous récupérons à intervalles régulier la position GPS inférée par le téléphone, et nous l'utilisons pour interroger la base de données WiGLE afin d'obtenir les adresses MAC des points d'accès Wi-Fi et des appareils Bluetooth à proximité. Ces adresses MAC sont ensuite émises à l'aide de l'outil mdk3 \cite{aspj_mdk3_2013} afin d'êtres captées par le téléphone instrumentalisé.

\textit{mdk3} est un outil très puissant permettant l'analyse de réseaux Wi-Fi. Il comporte de nombreuses fonctionnalités, majoritairement agressives, permettant par exemple de bruteforcer le MAC ou le SSID d'un access point.

Un access point envoie régulièrement des Beacon Frame pour signaler sa présence et donner ses caractéristiques (SSID, cryptage...). Avec une carte Wi-Fi en monitor mode, mdk3 nous permet de diffuser un grand nombre de Beacon Frame simulant ainsi la présence d'access point avec des adresses MAC différentes.

Afin de s'assurer de la pertinence de cette méthode, nous avons étudié l'influence du nombre de points d'accès et de leur localisation sur les coordonnées inférées par le service de géolocalisation de Google. Nous envoyons donc des requêtes de localisation contenant des adresses MAC de points d'accès Wi-Fi à la fois à San Francisco et à Kyoto, en proportion différente.

\newcommand{\green}{\cellcolor{green!50}}
\newcommand{\red}{\cellcolor{red!50}}
\newcommand{\yellow}{\cellcolor{yellow!80}}
\begin{table}
\centering
\begin{tabular} {| m{4.5cm} | m{0.6cm}| m{0.6cm} | m{0.6cm} | m{0.6cm} | m{0.6cm} | m{0.6cm} | m{0.6cm} | m{0.6cm} | m{0.6cm} |}
 \hline
 AP San Francisco / Kyoto & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7   \\
 \hline
 0  & \cellcolor{black} & \red & \red & \red & \red & \red & \red & \red     \\
 \hline
 1 & \green & \yellow & \yellow & \red & \red & \red & \red & \red  \\
 \hline
 2 & \green & \green & \green & \yellow & \red & \red & \red & \red  \\
 \hline
 3 & \green & \green & \green & \green & \yellow & \red & \red & \red  \\
 \hline
 4 & \green & \green & \green & \green & \green & \yellow & \yellow & \red  \\
 \hline
 5 & \green & \green & \green & \green & \green & \green & \green & \yellow  \\
 \hline
\end{tabular} 
\vspace{10pt}
\setlength{\belowcaptionskip}{-10pt}
\caption{\label{tab:table-name} Localisation renvoyée par le geolocation service de Google (vert: San Francisco, rouge: Kyoto, jaune: impossible de déterminer la position}
\end{table}

On constate alors que le service de géolocalisation ignore les points d'accès qui sont en infériorité numérique. Lorsque qu'ils sont en proportion à peu près égale (en jaune sur le schéma), les points d'accès sont jugés non pertinents et le service utilise donc l'adresse IP, ce qui dégrade beaucoup la précision (environ 2km au lieu de 150m). Cela nous permet de conclure qu'il est possible de noyer les points d'accès réellement présents par l'émission de points d'accès fictifs, et ainsi de tromper la part de détermination de la position utilisant le Wi-Fi. 

Enfin, nous utilisons un VPN afin d'obtenir une adresse IP proche du lieu de déplacement de notre utilisateur fictif.

Ce protocole expérimental est sujet à un certain nombre de limitations pratiques. 
Tout d'abord, l'émission du signal GPS doit être effectué sur la bande radio L1 située à une fréquence de 1575.42 MHz. Cependant, le modèle d'antenne en notre possession (ANT500) ne possède qu'une bande d'utilisation allant de 75 MHz à 1 GHz. D'autre part, l'horloge interne de notre radio logicielle (HackRF) possède un oscillateur interne ayant une stabilité de 20 ppm, tandis qu'une stabilité inférieure à 0.5 ppm est nécessaire pour obtenir une stabilité du signal GPS \cite{kao_miniature_2014}. Pour résoudre ces problèmes, nous nous sommes procuré une antenne active émettant sur la bande L1 ainsi qu'un oscillateur à quartz compensé en température (TCXO) avec une stabilité de 0.1 ppm. 

Ensuite, l'API de WiGLE est à l'origine limitée à 5 requêtes quotidiennes. Bien qu'ayant obtenu une dérogation de l'auteur du projet afin de pouvoir effectuer 250 requêtes par jour, cette limitation empêche le passage à l'échelle de l'expérimentation. En effet, nous aurions souhaité mettre à jour les adresses MAC diffusées toutes les 10 secondes, ce qui ne nous aurait permis de simuler qu'une quarantaine de minutes de déplacement en cumulé pour nos utilisateurs avant d'atteindre ces limites quotidiennes.

Enfin, il ne nous a pas été possible d'éliminer certaines variables externes liées au bruit ambiant. Nous n'avons trouvé aucune zone sans point d'accès Wi-Fi, sans réseau et sans aucun signal GPS. L'obscurité de l'algorithme de détermination de la position s'est révélé être un obstacle majeur aux expérimentations. 

Ce protocole nous a permis d'obtenir des positions sur la plupart des téléphones à notre disposition, et nous avons réussi à faire parcourir à un de nos téléphones un trajet d'une dizaine de minutes sur Google Maps dans la ville d'Austin au Texas. 
Cependant, il est envisageable qu'au delà des vecteurs de détermination de la position en temps réel, d'autres variables interviennent afin de juger de la plausibilité de la localisation. Pour tromper de manière

Enfin, nous n'avons pas expérimenté avec le vecteur de localisation par antenne de réseau mobile, car cela nécessite une radio full-duplex tandis que le HackRF en notre possession n'est qu'half-duplex : il permet d'émettre et de recevoir des signaux, mais pas les deux simultanément. 

\subsection{Création d'identités}

Afin d'étudier l'impact de la géolocalisation sur le ciblage publicitaire, il est nécessaire d'annuler l'influence des autres variables qui entrent en jeu. Pour ce faire, nous avons créé une flotte d'adresses e-mail servant à alimenter nos différents comptes. La tâche n'est pas aisée car il y a énormément de variables qui peuvent influencer le contenu publicitaire, et nous souhaitons étudier l'influence d'une seule d'entre elles : la localisation. Il s'agit donc de créer une identité assez banale, pour obtenir des publicités, sans qu'elles ne soient influencées par nos centres d'intérêt, mais par notre position.

Nous avons vite été confrontés à des difficultés pour créer de telles identités. Les comptes étant totalement vierges, nous n'avions pas de contenu, et donc pas de publicités. En effet, il est légitime pour un annonceur de ne pas vouloir payer pour atteindre un utilisateur dont les centres d'intérêt ne sont pas encore déterminés. Nous avons donc essayé d'alimenter nos comptes pour créer des identités fictives : ajouter des amis et aimer des pages sur Facebook, suivre des comptes et poster sur Instagram, suivre des comptes sur Twitter. Au cours de cette démarche, nous avons été bloqués par l'algorithme de Facebook qui a assimilé notre comportement à celui d'un bot. Pour le débloquer, il nous a été demandé d'uploader une vidéo de notre visage au cours de laquelle nous devions effectuer certains mouvements. Nous avons essayé de le tromper avec un modèle de tête 3D en le manipulant, sans succès. Malgré nos efforts, nous n'avons réussi à obtenir que quelques encarts publicitaires sur Facebook, mais aucun sur Twitter, Instagram ou TikTok. Les hypothèses que nous émettons sont que notre comportement est peut-être détecté comme frauduleux, et que l'apparition de publicités est soumis à un délai initial permettant de déterminer les centres d'intérêts de l'utilisateur.

Comme expliqué précédemment, il y a un grand nombre de variable aboutissant au ciblage publicitaire (âge, sexe, centres d'intérêt, orientation politique, localisation...). Cependant nous ne disposions que de trois téléphones mobiles, ce qui est peu pour produire des statistiques intéressantes. De plus, nous ne pouvions pas réinitialiser ou rooter ces téléphones. 
% expliquer pourquoi on ne peut pas utiliser un téléphone routé

Afin d'illustrer la difficulté combinatoire de cette création d'identité pour obtenir des statistiques utilisables, nous avons dressé une liste des variables pouvant potentiellement influer la manière dont un réseau social identifie la position d'un utilisateur. Celles-ci sont répertoriées en annexe \ref{appendix:variables}.

\subsection{Collecte des données}

Face à l'impossibilité de collecter le flux publicitaire en utilisant les API des plates-formes, nous avons mis en place d'autres moyens pour récupérer les publicités. 

\subsubsection{Web scraping}\label{collecte_web}

Nous avons tout d'abord utilisé une solution de collecte pour les publicités web. Cette première solution utilise un plugin Google Chrome - \textit{MyAdFinder} - pour réaliser un portefolio des publicités rencontrées sur Facebook. Ensuite, il est possible d'extraire le titre et le contenu de ces publicités en analysant le contenu HTML collecté. C'est un processus lent, puisqu'il implique la consommation active du fil d'actualité Facebook de l'utilisateur et qu'il ne suffit pas de défiler pour obtenir de nouvelles publicités, il faut également laisser un intervalle de temps entre chaque connexion.
De plus, cette approche ne permet de tirer que des conclusions restreintes sur le ciblage géographique, car le contenu web est davantage consommé par des utilisateurs à leur domicile, tandis que la consommation de contenu en déplacement se réalise davantage sur smartphone.

\subsubsection{Collecte visuelle}\label{collecte_mobile}

Afin d'automatiser la collecte de publicités davantage liées à la géolocalisation, nous avons également mis au point des protocoles de collecte de publicités sur mobile. À l'aide d'applications d'automatisation, nous effectuons un défilement permanent de l'écran ainsi que des captures d'écran à chaque intervalle de temps. Nous réalisons ensuite une segmentation des images capturées pour isoler chaque post du fil d'actualité. Nous filtrons ensuite les posts qui correspondent à du contenu sponsorisé, à l'aide d'un algorithme de pattern matching. Enfin, nous utilisons un outil de reconnaissance optique de caractères nommé Tesseract afin d'extraire le texte contenu dans chaque annonce publicitaire.

Ce protocole de collecte fonctionne correctement, cependant il n'est pas généralisable sous cette forme. Il est particulièrement adapté à un réseau social comme Twitter, ou l'écran peut contenir l'intégralité d'un post, à la différence de Facebook ou Instagram qui peut scinder les posts dépassant un certain nombre de caractères. Afin de capturer ces publications, il serait nécessaire d'introduire une navigation plus complexe capable de cliquer sur un lien pour afficher la totalité du post, tout en sachant que certains de ces posts longs affichent leur contenu sur la même page lors de l'utilisation de ce lien, tandis que d'autres s'ouvrent dans un nouveau contexte et nécessitent un retour sur la page principale afin de continuer la collecte. Cette navigation n'est pas possible avec l'outil Automate, mais peut être développée dans le cadre d'une application de collecte dédiée.
D'autre part, la chaîne de traitement des contenus sponsorisés pourrait être plus poussée dans le cas d'une collecte à grande échelle. En effet, les textes extraits des contenus publicitaires sont analysés manuellement, mais il est tout à fait envisageable d'utiliser un modèle de classification. Cela permettrait d'effectuer une analyse statistique plus poussée sur une quantité importante de données.

\subsubsection{Interception de paquets}

Afin de combiner l'efficacité et la transparence de cette collecte, nous proposons une solution hybride utilisant une attaque par Man In The Middle.
Le principe est de transmettre les requêtes du téléphone cible via un proxy. En installant le certificat TLS du proxy sur le téléphone cible, ce proxy peut crypter et décrypter le trafic HTTPS au fil des requêtes~\cite{noauthor_mitmproxy_2020}, ce qui permet d'observer en clair les réponses des API. Il est alors possible de faire du reverse engineering afin de comprendre la structure de ces réponses et d'en extraire les posts, ainsi que les informations publicitaires associées. 

De manière plus détaillée, l'interception de paquet se déroule de la manière suivante (Figure~\ref{fig:mitmproxy/concepts}).

\begin{itemize}
    \item Le téléphone émet une requête HTTP CONNECT afin de demander au proxy de créer un pipe qui permettra d'établir une connexion TLS entre le client et le serveur. Dans le cas d'un proxy classique, ce pipe est opaque au proxy qui ne fait que transférer des données cryptées
    \item Le proxy répond \textit{200 Connection established}, comme s'il avait réellement établi le pipe demandé
    \item Le téléphone pense alors parler au serveur et initie la connexion TLS par la phase de handshake, en indiquant notamment le nom du serveur auquel il souhaite se connecter
    \item Le proxy interrompt le handshake côté client et se connecte au serveur avec lequel le client souhaite communiquer
    \item Le serveur répond en présentant son certificat TLS
    \item Le proxy génère le certificat d'interception en remplaçant l'autorité de certification du serveur par celle du proxy, et en recopiant le Common Name ainsi que les Subject Alternative Names du serveur dans ce nouveau certificat
    \item Le proxy termine le handshake TLS avec le téléphone, qui est désormais connecté au serveur par une connexion TLS que le proxy peut décrypter
    \item Le téléphone communique avec le serveur et le proxy intercepte et décrypte à la volée le flux de requêtes et de réponses
\end{itemize}

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{mitmproxy_concepts.png}
    \caption{Fonctionnement du proxy utilisé pour intercepter les requêtes}
    \label{fig:mitmproxy/concepts}
\end{figure}

Plusieurs obstacles empêchent cette solution de fonctionner parfaitement. Tout d'abord, depuis Août 2016 et la sortie d'Android Nougat (7.0), les applications Android ne font plus confiance par défaut aux certificats installés par les utilisateurs~\cite{chad_brubaker_changes_2016}. 
Plusieurs solutions sont envisageables pour contourner cette mesure de sécurité. La plus simple consiste à utiliser la version mobile de l'application dans un navigateur tels que Firefox ou Chrome, car les navigateurs testés font confiance aux certificats utilisateurs. La seconde consiste à patcher les APK des applications afin de forcer la confiance dans les certificats utilisateurs. Cette méthode s'est avérée infructueuse car les organisations ciblées ont recours à l'obfuscation de leurs applications ce qui rend ardue leur décompilation. La troisième solution consiste à installer le certificat utilisateur dans le registre des certificats système. Ceci n'est possible qu'avec un appareil rooté, et n'est pas garanti de fonctionner si les applications mettent en place du certificate pinning~\cite{sleevi_rfc7469_2015}. La dernière solution consiste à intégrer les programmes de bug bounty mis en place afin de pouvoir utilser cette solution légalement. C'est le cas du programme Whitehat~\cite{facebook_whitehat_2020} de Facebook, qui permet entre autres de faire confiance aux certificats utilisateurs, et ainsi d'utiliser ce protocole de collecte sur Facebook, Instagram, Whatsapp et les autres applications développées par Facebook.

Cette méthode nous a permis de collecter des publicités de manière quasi automatique, mais elle repose sur l'hypothèse de stabilité du format des requêtes interceptées. Cette hypothèse n'est cependant pas vérifiée en pratique, comme nous avons pu l'observer début Janvier lors de l'introduction d'une nouvelle stratégie d'encodage des réponses par l'application Facebook. La mise en place de l'algorithme de compression \textit{zstd}~\cite{collet_zstandard_2018} qui utilise des dictionnaires pour optimiser la vitesse et le ratio de compression pour des fichiers de petite taille empêche le proxy de décoder les requêtes et donc d'en extraire les publicités.

Nous avons aussi tenté d'utiliser cette méthode pour instrumentaliser la position du téléphone en modifiant les requêtes qui transmettent nos données de géolocalisation aux serveurs applicatifs. Cela permettrait d'avoir un contrôle total sur les données transférées. Cependant, les requêtes modifiées n'étaient pas acceptées par le serveur à cause d'erreurs d'authentification. Nous en concluons que ces serveurs mettent en place un mécanisme empêchant la modification de requêtes à la volée.

\section{Résultats}\label{analyse_dataset}

La technique d'interception de paquets nous a permis de collecter un jeu de données publicitaire. Ce dataset contient des publicités récoltées sur les applications mobiles de Facebook et Instagram, ainsi que sur les versions mobiles des sites de Facebook et Twitter. Il contient 10396 publicités, pour une collecte qui s'étend du 27 novembre au 14 janvier, et collecte du contenu sponsorisé sur des comptes appartenant à 6 identités différentes. Il serait intéressant d'enrichir ce dataset avec d'avantages d'utilisateurs réels, et de diversifier l'échantillon pour avoir représentation plus hétérogène de la population. En effet, la collecte a été réalisée sur nos comptes personnels, et nous avons beaucoup de variables d'identité communes (âge, profession, lieu d'études). 

Le réseau social qui fournit la plus grande quantité de publicités est Instagram, sur lequel nous collectons 7270 publicités et 360 dans la section \textit{Stories}. La collecte est majoritairement réalisée le jeudi entre 8h et 18h, avec un maximum à 14h. 

Les auteurs de publicités sont un moyen privilégié pour déterminer si une publicité a été ciblée géographiquement, car ils peuvent contenir dans leur appellation le nom de la ville, de la localité, du département ou de la région dans laquelle ils se trouvent. Ainsi, nous avons pu identifier des petits commerces, des grandes enseignes, des opticiens, des restaurants, des salles de sport, des campagnes de promotion du tourisme, des informations de service public ("La voie de gauche sera réservée au co-voiturage), des écoles d'enseignement supérieur, des espaces ludiques. Avec cet élément comme facteur d'identification, nous observons que 1,06\% des publicités du dataset sont géociblés. Ce pourcentage varie sur les lieux de la collecte. Sur nos six points de collecte (New York, Aude, Hautes Alpes, Métropole de Lyon, Morbihan, Mayenne, Somme), les lieux les plus sollicités sont la Métropole de Lyon avec 6,4\%, suivi de la Mayenne et du Morbihan avec respectivement 3,7\% et 2,5\%. Le faible pourcentage dans les autres lieux de collecte peut s'expliquer par le fait que ce sont des lieux de campagne plus reculés, où l'on ne trouve pas nécessairement de commerces à proximité. Même s'il y a de petites différences, on peut remarquer que ce pourcentage est globalement faible par rapport à toutes les publicités que nous consommons. D'une part, avec cette méthode nous n'identifions pas toutes les publicités géociblées comme nous le détaillons ensuite, d'autre part, nous avons effectué les collectes dans un temps rapproché parfois sans s'arrêter : nous supposons l'existence d'un quota de publicités proposées aux utilisateurs, car dans une durée de temps déterminée, plus on collecte de publicités et plus ce pourcentage tend à diminuer.

Avec cette méthode, nous avons remarqué que Facebook était le réseau social qui avait le plus de publicités géociblés (3,2\% sur l'application et 3,4\% sur le navigateur). Sur Instagram, nous avons obtenu 0,4\% de publicités géociblés sur l'application et 1,4\% dans la section /textit{stories}. Sur le navigateur Twitter en revanche, nous n'avons pas été en mesure d'identifier des publicités géociblés.

Idéalement, il ne faudrait pas se limiter à cette méthode naïve pour identifier une publicité comme étant ciblée géographiquement ; en effet il n'existe pas seulement des raisons commerciales pour vouloir cibler géographiquement une zone. Par exemple, même si la publicité politique est interdite dans les mois qui précèdent une élection en France, on note aux États-Unis que les candidats choisissent les états incertains dans lesquels ils allouent un budget plus important. De même, certains groupuscules peuvent avoir intérêt à cibler un évènement regroupant des personnes avec la même identité politique ou idéologique. 

Pour le premier point évoqué, la publicité politique, nous avons essayé de d'obtenir des publicités américaines. Nous avons un échantillon de 3862 publicités dans lequel trois vecteurs (IP, GPS, et Wi-Fi) de détermination de la position sont pointés vers New York. Pourtant nous n'avons pas réussi à identifier de publicités américaines. Une des hypothèse envisagée est que d'autres variables sont prises en compte par le réseau social pour les publicités à l'étranger, et même si un individu voyage, il ne lui est pas proposé le même contenu publicitaire, en particulier en terme de politique. La seconde hypothèse est qu'il faut attendre plus longtemps avant de recevoir du contenu ciblé lors d'un voyage. En effet, nous avons collecté toutes les publicités à New York le même jour, ce qui représente un temps très court d'une part, et d'autre part l'aspect fictif du déplacement a pu être idéntifié puisque du point de vu du réseau social, le téléphone s'est téléporté entre la France et le centre de New York.

Pour le second point, il n'a pas été possible de collecter des publicités sur des points stratégiques de rassemblement de foule puisque ceux-ci n'ont pas eu lieu à cause de la Covid-19.

Nous avons également observé que les réseaux sociaux avaient une mémoire de notre localisation. Par exemple, notre calcul du pourcentage de publicités géociblés intègre tous les points de collecte. Ainsi, le pourcentage de publicités géociblées à New York est non nul, puisque parmi les publicités collectées, nous avons encore des publicités de commerces Français. De même, lorsqu'un utilisateur se déplace en France, il continue de recevoir des publicités de son lieu d'habitation principal. Remarquons tout de même que le pourcentage de publicités géociblées à New York est le plus faible parmi tous les lieux de collecte (0.35\%), ce qui peut montrer que l'incohérence a potentiellement été perçue par les réseaux sociaux.

En analysant globalement le dataset, nous n'identifions alors plus ces publicités géociblés de niche, mais pouvons affirmer ceci : la majorité des publicités sont liés à notre profil en tant qu'individus. Sur Twitter, les auteurs de publicité les plus fréquents sont en premier les fast food McDonald's et Burger King. Viennent ensuite une quantité importante de marques et entreprises en lien avec l'informatique : on retrouve Microsoft Research, Apple, Samsung FR, Microsoft Azure, Playstation France, Nintendo France, Dropbox, Lenovo France, Amazon Prime Video, Chrome developers, Dell. Les sujets majoritaires suivant sont la banque, le voyage, les opérateurs téléphoniques.
Sur Facebook, le contenu est en majorité consacré à la vente (Cabaia, Displate, Persol Eyewear, Zalando) et au divertissement (Spotify, Disney+, Canal+), mais on retrouve aussi les thèmes précédents (Microsoft Azure, Wix Français, Webflow, Oculus).

Pour rendre compte de tous ces éléments, nous proposons une infographie en annexe \ref{appendix:graphs}.

\section{Conclusion}\label{conclusion}

Lors de ce projet, nous avons mis au point des techniques et des outils permettant d'instrumentaliser la position d'un smartphone ainsi que de collecter les publicités sur les applications mobiles de réseaux sociaux majeurs. 
L'instrumentalisation de la position utilise les vecteurs GPS, Wi-Fi et Bluetooth, mais il serait intéressant d'explorer le vecteur de réseau mobile que nous n'avons pas étudié par manque de matériel. 
La collecte de publicités peut être réalisée soit par reconnaissance optique de caractères, soit par interception de paquets. La première méthode est plus discrète et moins intrusive, mais la seconde est plus efficace. 
Ces méthodes nous permettent de publier un jeu de données contenant plus de 10000 publicités collectées par 6 profils différents sur une période de 2 mois.
Il n'a pas été observé de corrélation directe entre une position fictive et la suggestion de contenu sponsorisé géolocalisé.
Bien que ce ne soit pas l'objectif premier, ce projet nous a permis d'avoir un aperçu technique de l'ampleur de la collecte de données de géolocalisation des utilisateurs de réseaux sociaux.

% ---- Bibliography ----

\bibliographystyle{splncs04} %ieeetr
\bibliography{psat-geoloc}

\clearpage

\begin{appendix}
    \section{Variables de détermination de position}
    \label{appendix:variables}
    \begin{itemize}
    \item Variables liées aux services de localisation
    
    \begin{itemize}
      \item Signaux GPS
      \item Points d'accès Wi-Fi
      \item Réseaux mobiles
      \item Adresse IP
      \item Historique de localisation
    \end{itemize}
    
    \item Variables liées aux téléphones
    
    \begin{itemize}
      \item Langue de l'interface
      \item Adresse mac du téléphone, qui permet d'inférer le Vendor ID
      \item Identifiant du pays de la carte SIM et de l'opérateur de téléphonie mobile
      \item Mode de localisation activé (GPS ou Fused Location)
      \item Comptes connectés sur le téléphone : compte Google nécessaire pour télécharger des applications sur le Play Store
    \end{itemize}
    
    \item Variables liées aux applications
    
    \begin{itemize}
        \item Permission d'utilisation d'accès aux services de localisation
        \item Liste des informations renseignées sur le profil : lieu d'habitation, lieu d'études, lieu de travail
        \item Informations inférées grâce au graphe de relations, d'appartenance à des groupes, des pages aimées (restaurants d'une ville, petites annonces d'un quartier)
    \end{itemize}
    
\end{itemize}

\section{Infographie}
\label{appendix:graphs}
\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{infographic/source-1.png}

\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.7\linewidth]{infographic/source-2.png}

\end{figure}

\begin{figure}
    \centering
    \centerline{\includegraphics[width=1.5\linewidth]{infographic/author_location.png}}

\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{infographic/twitter.png}

\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{infographic/facebook.png}

\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{infographic/gps_and_ip_loc.png}

\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{infographic/gps_coordinates.png}

\end{figure}


\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{infographic/percent.png}

\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.7\linewidth]{infographic/percent-geotarget.png}
    
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{infographic/time.png}
    
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{infographic/day.png}
    
\end{figure}

\end{appendix}

\end{document}


